{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1, 8-Puzzle Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your homework must be implemented in this Notebook file. \n",
    "You can add as many cells as you want. However, you are not allowed to touch the code below the line \"=============\".\n",
    "You need to implement the three (four for grads) searching functions and the print result functions.\n",
    "For the searching functions, feel free to customize the return data types and parameter lists as long as the function name is as required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#implementation of function \"Iterative_deepening_DFS\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "goal_state = np.array([[0, 1, 2],\n",
    "                       [3, 4, 5],\n",
    "                       [6, 7, 8]])\n",
    "class Node_DFS:\n",
    "    def __init__(self,data,parent,cost_g):\n",
    "        self.data = data\n",
    "        self.L1 = None\n",
    "        self.L2 = None\n",
    "        self.R1 = None\n",
    "        self.R2 = None\n",
    "        self.parent = parent\n",
    "        self.cost_g = cost_g\n",
    "    \n",
    "    def possibility_L1(self):\n",
    "        index_of_zero=np.where(self.data == 0)\n",
    "        if index_of_zero[1] == 0:\n",
    "            return False\n",
    "        else:\n",
    "            temp = self.data[index_of_zero[0],index_of_zero[1]-1]\n",
    "            new_data = self.data.copy()\n",
    "            new_data[index_of_zero[0],index_of_zero[1]] = temp\n",
    "            new_data[index_of_zero[0],index_of_zero[1]-1] = 0\n",
    "            return new_data,True\n",
    "       \n",
    "    \n",
    "    def possibility_L2(self):\n",
    "        index_of_zero=np.where(self.data == 0)\n",
    "        if index_of_zero[0] == 2:\n",
    "            return False\n",
    "        else:\n",
    "            temp = self.data[index_of_zero[0]+1,index_of_zero[1]]\n",
    "            new_data = self.data.copy()\n",
    "            new_data[index_of_zero[0],index_of_zero[1]] = temp\n",
    "            new_data[index_of_zero[0]+1,index_of_zero[1]] = 0\n",
    "            return new_data,True\n",
    "        \n",
    "        \n",
    "    def possibility_R1(self):\n",
    "        index_of_zero=np.where(self.data == 0)\n",
    "        if index_of_zero[1] == 2:\n",
    "            return False\n",
    "        else:\n",
    "            temp = self.data[index_of_zero[0],index_of_zero[1]+1]\n",
    "            new_data = self.data.copy()\n",
    "            new_data[index_of_zero[0],index_of_zero[1]] = temp\n",
    "            new_data[index_of_zero[0],index_of_zero[1]+1] = 0\n",
    "            return new_data,True\n",
    "            \n",
    "    def possibility_R2(self):\n",
    "        index_of_zero=np.where(self.data == 0)\n",
    "        if index_of_zero[0] == 0:\n",
    "            return False\n",
    "        else:\n",
    "            temp = self.data[index_of_zero[0]-1,index_of_zero[1]]\n",
    "            new_data = self.data.copy()\n",
    "            new_data[index_of_zero[0],index_of_zero[1]] = temp\n",
    "            new_data[index_of_zero[0]-1,index_of_zero[1]] = 0\n",
    "            return new_data,True\n",
    "        \n",
    "    def Iterative_deepening_DFS(self):\n",
    "        iteration_counter = 0\n",
    "        for depth in range(100):\n",
    "        \n",
    "            queue = [self] \n",
    "            frontier = set([]) \n",
    "            cutoff = [0]\n",
    "            g_queue = [0]\n",
    "            iteration_counter += 1\n",
    "\n",
    "            while queue:\n",
    "\n",
    "                current_node = queue.pop(0) \n",
    "                #print(current_node.data)\n",
    "                   \n",
    "                current_cutoff =cutoff.pop(0)\n",
    "                current_g = g_queue.pop(0)\n",
    "                \n",
    "                frontier.add(tuple(current_node.data.reshape(1,9)[0]))\n",
    "\n",
    "                if np.array_equal(current_node.data,goal_state):\n",
    "                    steps = current_node.print_result_DFS()\n",
    "                    return steps,iteration_counter\n",
    "\n",
    "                else:              \n",
    "                    if current_cutoff < depth:\n",
    "                          \n",
    "                        if current_node.possibility_R2():\n",
    "                            new_data,garbage = current_node.possibility_R2()\n",
    "                    \n",
    "                            if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                                cost_g = current_g+1\n",
    "                                current_node.R2 = Node_DFS(data=new_data,parent=current_node,cost_g=cost_g)\n",
    "                                queue.insert(0,current_node.R2)\n",
    "                                cutoff.insert(0,current_cutoff+1)\n",
    "                                g_queue.insert(0,cost_g)\n",
    "\n",
    "                        if current_node.possibility_R1():\n",
    "                            new_data,garbage = current_node.possibility_R1()\n",
    "                    \n",
    "                            if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                                cost_g = current_g+1\n",
    "                                current_node.R1 = Node_DFS(data=new_data,parent=current_node,cost_g=cost_g)\n",
    "                                queue.insert(0,current_node.R1)\n",
    "                                cutoff.insert(0,current_cutoff+1)\n",
    "                                g_queue.insert(0,cost_g)\n",
    "\n",
    "                        if current_node.possibility_L2():\n",
    "                            new_data,garbage = current_node.possibility_L2()\n",
    "                    \n",
    "                            if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                                cost_g = current_g+1\n",
    "                                current_node.L2 = Node_DFS(data=new_data,parent=current_node,cost_g=cost_g)\n",
    "                                queue.insert(0,current_node.L2)\n",
    "                                cutoff.insert(0,current_cutoff+1)\n",
    "                                g_queue.insert(0,cost_g)\n",
    "                                \n",
    "                                \n",
    "                        if current_node.possibility_L1():\n",
    "                            new_data,garbage = current_node.possibility_L1()\n",
    "                    \n",
    "                            if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                                cost_g = current_g+1\n",
    "                                current_node.L1 = Node_DFS(data=new_data,parent=current_node,cost_g=cost_g)\n",
    "                                queue.insert(0,current_node.L1)\n",
    "                                cutoff.insert(0,current_cutoff+1)\n",
    "                                g_queue.insert(0,cost_g)\n",
    "                                \n",
    "    def print_result_DFS(self):\n",
    "        data_tracking = [self.data]\n",
    "        g_tracking = [self.cost_g]\n",
    "        \n",
    "        while self.parent:\n",
    "            self = self.parent\n",
    "            data_tracking.append(self.data)\n",
    "            g_tracking.append(self.cost_g)\n",
    "            \n",
    "        print ('Solution of the first Scenario(IterativeDFS):')\n",
    "        while data_tracking:\n",
    "            print (data_tracking.pop())\n",
    "            print ('to') \n",
    "        return len(g_tracking)\n",
    "    \n",
    "    \n",
    "    def deepeningDFS_withoutprint(self):\n",
    "        iteration_counter = 0\n",
    "        for depth in range(100):\n",
    "        \n",
    "            queue = [self] \n",
    "            frontier = set([]) \n",
    "            cutoff = [0]\n",
    "            g_queue = [0]\n",
    "            iteration_counter += 1\n",
    "\n",
    "            while queue:\n",
    "\n",
    "                current_node = queue.pop(0) \n",
    "                #print(current_node.data)\n",
    "                   \n",
    "                current_cutoff =cutoff.pop(0)\n",
    "                current_g = g_queue.pop(0)\n",
    "                \n",
    "                frontier.add(tuple(current_node.data.reshape(1,9)[0]))\n",
    "\n",
    "                if np.array_equal(current_node.data,goal_state):\n",
    "                    steps = current_node.without_result_DFS()\n",
    "                    return steps,iteration_counter\n",
    "\n",
    "                else:              \n",
    "                    if current_cutoff < depth:\n",
    "                          \n",
    "                        if current_node.possibility_R2():\n",
    "                            new_data,garbage = current_node.possibility_R2()\n",
    "                    \n",
    "                            if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                                cost_g = current_g+1\n",
    "                                current_node.R2 = Node_DFS(data=new_data,parent=current_node,cost_g=cost_g)\n",
    "                                queue.insert(0,current_node.R2)\n",
    "                                cutoff.insert(0,current_cutoff+1)\n",
    "                                g_queue.insert(0,cost_g)\n",
    "\n",
    "                        if current_node.possibility_R1():\n",
    "                            new_data,garbage = current_node.possibility_R1()\n",
    "                    \n",
    "                            if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                                cost_g = current_g+1\n",
    "                                current_node.R1 = Node_DFS(data=new_data,parent=current_node,cost_g=cost_g)\n",
    "                                queue.insert(0,current_node.R1)\n",
    "                                cutoff.insert(0,current_cutoff+1)\n",
    "                                g_queue.insert(0,cost_g)\n",
    "                               \n",
    "\n",
    "                        if current_node.possibility_L2():\n",
    "                            new_data,garbage = current_node.possibility_L2()\n",
    "                    \n",
    "                            if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                                cost_g = current_g+1\n",
    "                                current_node.L2 = Node_DFS(data=new_data,parent=current_node,cost_g=cost_g)\n",
    "                                queue.insert(0,current_node.L2)\n",
    "                                cutoff.insert(0,current_cutoff+1)\n",
    "                                g_queue.insert(0,cost_g)\n",
    "                                \n",
    "                                \n",
    "                        if current_node.possibility_L1():\n",
    "                            new_data,garbage = current_node.possibility_L1()\n",
    "                    \n",
    "                            if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                                cost_g = current_g+1\n",
    "                                current_node.L1 = Node_DFS(data=new_data,parent=current_node,cost_g=cost_g)\n",
    "                                queue.insert(0,current_node.L1)\n",
    "                                cutoff.insert(0,current_cutoff+1)\n",
    "                                g_queue.insert(0,cost_g)\n",
    "                                \n",
    "                                \n",
    "    def without_result_DFS(self):\n",
    "        g_tracking = [self.cost_g]\n",
    "        \n",
    "        while self.parent:\n",
    "            self = self.parent\n",
    "            g_tracking.append(self.cost_g)\n",
    "            \n",
    "        return len(g_tracking)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#implementation of function \"aStarMisplacedTiles\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "goal_state = np.array([[0, 1, 2],\n",
    "                       [3, 4, 5],\n",
    "                       [6, 7, 8]])\n",
    "class Node_astar_misplaced:\n",
    "    def __init__(self,data,parent,cost_g,cost_h):\n",
    "        self.data = data\n",
    "        self.parent = parent\n",
    "        self.cost_g = cost_g\n",
    "        self.cost_h = cost_h\n",
    "        self.L1 = None\n",
    "        self.L2 = None\n",
    "        self.R1 = None\n",
    "        self.R2 = None\n",
    "    \n",
    "    def possibility_L1(self):\n",
    "        index_of_zero=np.where(self.data == 0)\n",
    "        if index_of_zero[1] == 0:\n",
    "            return False\n",
    "        else:\n",
    "            temp = self.data[index_of_zero[0],index_of_zero[1]-1]\n",
    "            new_data = self.data.copy()\n",
    "            new_data[index_of_zero[0],index_of_zero[1]] = temp\n",
    "            new_data[index_of_zero[0],index_of_zero[1]-1] = 0\n",
    "            return new_data,True\n",
    "       \n",
    "    \n",
    "    def possibility_L2(self):\n",
    "        index_of_zero=np.where(self.data == 0)\n",
    "        if index_of_zero[0] == 2:\n",
    "            return False\n",
    "        else:\n",
    "            temp = self.data[index_of_zero[0]+1,index_of_zero[1]]\n",
    "            new_data = self.data.copy()\n",
    "            new_data[index_of_zero[0],index_of_zero[1]] = temp\n",
    "            new_data[index_of_zero[0]+1,index_of_zero[1]] = 0\n",
    "            return new_data,True\n",
    "        \n",
    "        \n",
    "    def possibility_R1(self):\n",
    "        index_of_zero=np.where(self.data == 0)\n",
    "        if index_of_zero[1] == 2:\n",
    "            return False\n",
    "        else:\n",
    "            temp = self.data[index_of_zero[0],index_of_zero[1]+1]\n",
    "            new_data = self.data.copy()\n",
    "            new_data[index_of_zero[0],index_of_zero[1]] = temp\n",
    "            new_data[index_of_zero[0],index_of_zero[1]+1] = 0\n",
    "            return new_data,True\n",
    "            \n",
    "    def possibility_R2(self):\n",
    "        index_of_zero=np.where(self.data == 0)\n",
    "        if index_of_zero[0] == 0:\n",
    "            return False\n",
    "        else:\n",
    "            temp = self.data[index_of_zero[0]-1,index_of_zero[1]]\n",
    "            new_data = self.data.copy()\n",
    "            new_data[index_of_zero[0],index_of_zero[1]] = temp\n",
    "            new_data[index_of_zero[0]-1,index_of_zero[1]] = 0\n",
    "            return new_data,True\n",
    "        \n",
    "    def aStarMisplacedTiles(self):\n",
    "        \n",
    "        queue = [(self,0)] \n",
    "        frontier = set([])\n",
    "        g_queue = [(0,0)]\n",
    "        iteration_counter = 0\n",
    "            \n",
    "\n",
    "        while queue:\n",
    "                queue = sorted(queue, key=lambda x:x[1])\n",
    "                current_node = queue.pop(0)[0]\n",
    "                g_queue = sorted(g_queue, key=lambda x:x[1])\n",
    "                current_g = g_queue.pop(0)[0]\n",
    "                #print(current_node.data)\n",
    "                \n",
    "                frontier.add(tuple(current_node.data.reshape(1,9)[0]))\n",
    "                iteration_counter += 1\n",
    "            \n",
    "                if np.array_equal(current_node.data,goal_state):\n",
    "                    steps=current_node.print_result_astar_misplaced()\n",
    "                    return steps,iteration_counter\n",
    "\n",
    "                else:              \n",
    "                    if current_node.possibility_R2():\n",
    "                        new_data,garbage = current_node.possibility_R2()\n",
    "                        if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                            cost_g = current_g+1\n",
    "                            temp_h=np.sum(new_data!=goal_state)\n",
    "                            total_cost = temp_h + cost_g\n",
    "                            current_node.R2 = Node_astar_misplaced(data=new_data,parent=current_node,cost_g=cost_g,cost_h=temp_h)\n",
    "                            queue.append((current_node.R2,total_cost))\n",
    "                            g_queue.append((cost_g,total_cost))\n",
    "\n",
    "                    if current_node.possibility_R1():\n",
    "                        new_data,garbage = current_node.possibility_R1()\n",
    "                        if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                            cost_g = current_g+1\n",
    "                            temp_h=np.sum(new_data!=goal_state)\n",
    "                            total_cost = temp_h + cost_g\n",
    "                            current_node.R1 = Node_astar_misplaced(data=new_data,parent=current_node,cost_g=cost_g,cost_h=temp_h)\n",
    "                            queue.append((current_node.R1,total_cost))\n",
    "                            g_queue.append((cost_g,total_cost))                               \n",
    "\n",
    "                    if current_node.possibility_L2():\n",
    "                        new_data,garbage = current_node.possibility_L2()\n",
    "                        if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                            cost_g = current_g+1\n",
    "                            temp_h=np.sum(new_data!=goal_state)\n",
    "                            total_cost = temp_h + cost_g \n",
    "                            current_node.L2 = Node_astar_misplaced(data=new_data,parent=current_node,cost_g=cost_g,cost_h=temp_h)\n",
    "                            queue.append((current_node.L2,total_cost))\n",
    "                            g_queue.append((cost_g,total_cost))\n",
    "                                \n",
    "                    if current_node.possibility_L1():\n",
    "                        new_data,garbage = current_node.possibility_L1()\n",
    "                        if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                            cost_g = current_g+1\n",
    "                            temp_h=np.sum(new_data!=goal_state)\n",
    "                            total_cost = temp_h + cost_g\n",
    "                            current_node.L1 = Node_astar_misplaced(data=new_data,parent=current_node,cost_g=cost_g,cost_h=temp_h)\n",
    "                            queue.append((current_node.L1,total_cost))\n",
    "                            g_queue.append((cost_g,total_cost))\n",
    "                                \n",
    "                                \n",
    "    def print_result_astar_misplaced(self):\n",
    "        data_tracking = [self.data]\n",
    "        g_tracking = [self.cost_g]\n",
    "        \n",
    "        while self.parent:\n",
    "            self = self.parent\n",
    "            data_tracking.append(self.data)\n",
    "            \n",
    "            g_tracking.append(self.cost_g)\n",
    "        print ('Solution of the first Scenario(astr_misplaced):')\n",
    "        \n",
    "        while data_tracking:\n",
    "            print (data_tracking.pop())\n",
    "            #print(g_tracking.pop())\n",
    "            print ('to') \n",
    "            \n",
    "        return len(g_tracking)\n",
    "    \n",
    "    \n",
    "    def astar_misplaced_withoutprint(self):\n",
    "        \n",
    "        queue = [(self,0)] \n",
    "        frontier = set([])\n",
    "        g_queue = [(0,0)]\n",
    "        iteration_counter = 0\n",
    "            \n",
    "\n",
    "        while queue:\n",
    "                queue = sorted(queue, key=lambda x:x[1])\n",
    "                current_node = queue.pop(0)[0]\n",
    "                g_queue = sorted(g_queue, key=lambda x:x[1])\n",
    "                current_g = g_queue.pop(0)[0]\n",
    "                #print(current_node.data)\n",
    "                \n",
    "                frontier.add(tuple(current_node.data.reshape(1,9)[0]))\n",
    "                iteration_counter += 1\n",
    "\n",
    "                if np.array_equal(current_node.data,goal_state):\n",
    "                    steps=current_node.without_result_astar_misplaced()\n",
    "                    return steps,iteration_counter\n",
    "\n",
    "                else:              \n",
    "                    if current_node.possibility_R2():\n",
    "                        new_data,garbage = current_node.possibility_R2()\n",
    "                        if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                            cost_g = current_g+1\n",
    "                            temp_h=np.sum(new_data!=goal_state)\n",
    "                            total_cost = temp_h + cost_g\n",
    "                            current_node.R2 = Node_astar_misplaced(data=new_data,parent=current_node,cost_g=cost_g,cost_h=temp_h)\n",
    "                            queue.append((current_node.R2,total_cost))\n",
    "                            g_queue.append((cost_g,total_cost))\n",
    "\n",
    "                    if current_node.possibility_R1():\n",
    "                        new_data,garbage = current_node.possibility_R1()\n",
    "                        if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                            cost_g = current_g+1\n",
    "                            temp_h=np.sum(new_data!=goal_state)\n",
    "                            total_cost = temp_h + cost_g\n",
    "                            current_node.R1 = Node_astar_misplaced(data=new_data,parent=current_node,cost_g=cost_g,cost_h=temp_h)\n",
    "                            queue.append((current_node.R1,total_cost))\n",
    "                            g_queue.append((cost_g,total_cost))                               \n",
    "\n",
    "                    if current_node.possibility_L2():\n",
    "                        new_data,garbage = current_node.possibility_L2()\n",
    "                        if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                            cost_g = current_g+1\n",
    "                            temp_h=np.sum(new_data!=goal_state)\n",
    "                            total_cost = temp_h + cost_g \n",
    "                            current_node.L2 = Node_astar_misplaced(data=new_data,parent=current_node,cost_g=cost_g,cost_h=temp_h)\n",
    "                            queue.append((current_node.L2,total_cost))\n",
    "                            g_queue.append((cost_g,total_cost))\n",
    "                                \n",
    "                    if current_node.possibility_L1():\n",
    "                        new_data,garbage = current_node.possibility_L1()\n",
    "                        if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                            cost_g = current_g+1\n",
    "                            temp_h=np.sum(new_data!=goal_state)\n",
    "                            total_cost = temp_h + cost_g\n",
    "                            current_node.L1 = Node_astar_misplaced(data=new_data,parent=current_node,cost_g=cost_g,cost_h=temp_h)\n",
    "                            queue.append((current_node.L1,total_cost))\n",
    "                            g_queue.append((cost_g,total_cost))\n",
    "                                \n",
    "                                \n",
    "    def without_result_astar_misplaced(self):\n",
    "        g_tracking = [self.cost_g]\n",
    "        \n",
    "        while self.parent:\n",
    "            self = self.parent\n",
    "            g_tracking.append(self.cost_g)\n",
    "            \n",
    "        return len(g_tracking)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#implementation of function \"aStarManhattanDistance\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "goal_state = np.array([[0, 1, 2],\n",
    "                       [3, 4, 5],\n",
    "                       [6, 7, 8]])\n",
    "class Node_astar_manhattan:\n",
    "    def __init__(self,data,parent,cost_g,cost_h):\n",
    "        self.data = data\n",
    "        self.parent = parent\n",
    "        self.cost_g = cost_g\n",
    "        self.cost_h = cost_h\n",
    "        self.L1 = None\n",
    "        self.L2 = None\n",
    "        self.R1 = None\n",
    "        self.R2 = None\n",
    "    \n",
    "    def possibility_L1(self):\n",
    "        index_of_zero=np.where(self.data == 0)\n",
    "        if index_of_zero[1] == 0:\n",
    "            return False\n",
    "        else:\n",
    "            temp = self.data[index_of_zero[0],index_of_zero[1]-1]\n",
    "            new_data = self.data.copy()\n",
    "            new_data[index_of_zero[0],index_of_zero[1]] = temp\n",
    "            new_data[index_of_zero[0],index_of_zero[1]-1] = 0\n",
    "            return new_data,True\n",
    "       \n",
    "    \n",
    "    def possibility_L2(self):\n",
    "        index_of_zero=np.where(self.data == 0)\n",
    "        if index_of_zero[0] == 2:\n",
    "            return False\n",
    "        else:\n",
    "            temp = self.data[index_of_zero[0]+1,index_of_zero[1]]\n",
    "            new_data = self.data.copy()\n",
    "            new_data[index_of_zero[0],index_of_zero[1]] = temp\n",
    "            new_data[index_of_zero[0]+1,index_of_zero[1]] = 0\n",
    "            return new_data,True\n",
    "        \n",
    "        \n",
    "    def possibility_R1(self):\n",
    "        index_of_zero=np.where(self.data == 0)\n",
    "        if index_of_zero[1] == 2:\n",
    "            return False\n",
    "        else:\n",
    "            temp = self.data[index_of_zero[0],index_of_zero[1]+1]\n",
    "            new_data = self.data.copy()\n",
    "            new_data[index_of_zero[0],index_of_zero[1]] = temp\n",
    "            new_data[index_of_zero[0],index_of_zero[1]+1] = 0\n",
    "            return new_data,True\n",
    "            \n",
    "    def possibility_R2(self):\n",
    "        index_of_zero=np.where(self.data == 0)\n",
    "        if index_of_zero[0] == 0:\n",
    "            return False\n",
    "        else:\n",
    "            temp = self.data[index_of_zero[0]-1,index_of_zero[1]]\n",
    "            new_data = self.data.copy()\n",
    "            new_data[index_of_zero[0],index_of_zero[1]] = temp\n",
    "            new_data[index_of_zero[0]-1,index_of_zero[1]] = 0\n",
    "            return new_data,True\n",
    "        \n",
    "    def aStarManhattanDistance(self):\n",
    "        \n",
    "        queue = [(self,0)] \n",
    "        frontier = set([])\n",
    "        g_queue = [(0,0)]\n",
    "        iteration_counter = 0\n",
    "        \n",
    "            \n",
    "\n",
    "        while queue:\n",
    "                queue = sorted(queue, key=lambda x:x[1])\n",
    "                current_node = queue.pop(0)[0]\n",
    "                g_queue = sorted(g_queue, key=lambda x:x[1])\n",
    "                current_g = g_queue.pop(0)[0]\n",
    "                #print(current_node.data)\n",
    "                \n",
    "                frontier.add(tuple(current_node.data.reshape(1,9)[0]))\n",
    "                iteration_counter += 1\n",
    "\n",
    "                if np.array_equal(current_node.data,goal_state):\n",
    "                    steps=current_node.print_result_manhattan()\n",
    "                    return steps,iteration_counter\n",
    "\n",
    "                else:              \n",
    "                    if current_node.possibility_R2():\n",
    "                        new_data,garbage = current_node.possibility_R2()\n",
    "                        if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                            cost_g = current_g+1\n",
    "                            temp = new_data\n",
    "                            goal_position_dic = {0:(0,0),1:(0,1),2:(0,2),3:(1,0),4:(1,1),5:(1,2),6:(2,0),7:(2,1),8:(2,2)}\n",
    "                            temp_h=0\n",
    "                            for i in range(3):\n",
    "                                for j in range(3):\n",
    "                                    if temp[i,j] != 0:\n",
    "                                        temp_h += sum(abs(a-b) for a,b in zip((i,j), goal_position_dic[temp[i,j]]))\n",
    "                                        \n",
    "                            total_cost = temp_h + cost_g\n",
    "                            current_node.R2 = Node_astar_manhattan(data=new_data,parent=current_node,cost_g=cost_g,cost_h=temp_h)\n",
    "                            queue.append((current_node.R2,total_cost))\n",
    "                            g_queue.append((cost_g,total_cost))\n",
    "\n",
    "                    if current_node.possibility_R1():\n",
    "                        new_data,garbage = current_node.possibility_R1()\n",
    "                        if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                            cost_g = current_g+1\n",
    "                            temp = new_data\n",
    "                            goal_position_dic = {0:(0,0),1:(0,1),2:(0,2),3:(1,0),4:(1,1),5:(1,2),6:(2,0),7:(2,1),8:(2,2)}\n",
    "                            temp_h=0\n",
    "                            for i in range(3):\n",
    "                                for j in range(3):\n",
    "                                    if temp[i,j] != 0:\n",
    "                                        temp_h += sum(abs(a-b) for a,b in zip((i,j), goal_position_dic[temp[i,j]]))\n",
    "                                        \n",
    "                            total_cost = temp_h + cost_g\n",
    "                            current_node.R1 = Node_astar_manhattan(data=new_data,parent=current_node,cost_g=cost_g,cost_h=temp_h)\n",
    "                            queue.append((current_node.R1,total_cost))\n",
    "                            g_queue.append((cost_g,total_cost))                               \n",
    "\n",
    "                    if current_node.possibility_L2():\n",
    "                        new_data,garbage = current_node.possibility_L2()\n",
    "                        if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                            cost_g = current_g+1\n",
    "                            temp = new_data\n",
    "                            goal_position_dic = {0:(0,0),1:(0,1),2:(0,2),3:(1,0),4:(1,1),5:(1,2),6:(2,0),7:(2,1),8:(2,2)}\n",
    "                            temp_h=0\n",
    "                            for i in range(3):\n",
    "                                for j in range(3):\n",
    "                                    if temp[i,j] != 0:\n",
    "                                        temp_h += sum(abs(a-b) for a,b in zip((i,j), goal_position_dic[temp[i,j]]))\n",
    "                            \n",
    "                            total_cost = temp_h + cost_g \n",
    "                            current_node.L2 = Node_astar_manhattan(data=new_data,parent=current_node,cost_g=cost_g,cost_h=temp_h)\n",
    "                            queue.append((current_node.L2,total_cost))\n",
    "                            g_queue.append((cost_g,total_cost))\n",
    "                                \n",
    "                    if current_node.possibility_L1():\n",
    "                        new_data,garbage = current_node.possibility_L1()\n",
    "                        if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                            cost_g = current_g+1\n",
    "                            temp = new_data\n",
    "                            goal_position_dic = {0:(0,0),1:(0,1),2:(0,2),3:(1,0),4:(1,1),5:(1,2),6:(2,0),7:(2,1),8:(2,2)}\n",
    "                            temp_h=0\n",
    "                            for i in range(3):\n",
    "                                for j in range(3):\n",
    "                                    if temp[i,j] != 0:\n",
    "                                        temp_h += sum(abs(a-b) for a,b in zip((i,j), goal_position_dic[temp[i,j]]))\n",
    "                            \n",
    "                            total_cost = temp_h + cost_g\n",
    "                            current_node.L1 = Node_astar_manhattan(data=new_data,parent=current_node,cost_g=cost_g,cost_h=temp_h)\n",
    "                            queue.append((current_node.L1,total_cost))\n",
    "                            g_queue.append((cost_g,total_cost))\n",
    "                                \n",
    "                                \n",
    "    def print_result_manhattan(self):\n",
    "        data_tracking = [self.data]\n",
    "        g_tracking = [self.cost_g]\n",
    "        \n",
    "        while self.parent:\n",
    "            self = self.parent\n",
    "            data_tracking.append(self.data)\n",
    "            g_tracking.append(self.cost_g)\n",
    "        print ('Solution of the first Scenario(astar_manhattan):')\n",
    "        \n",
    "        while data_tracking:\n",
    "            print (data_tracking.pop())\n",
    "            print ('to')      \n",
    "        return len(g_tracking)\n",
    "    \n",
    "    def astar_manhattan_withoutprint(self):\n",
    "        \n",
    "        queue = [(self,0)] \n",
    "        frontier = set([])\n",
    "        g_queue = [(0,0)]\n",
    "        iteration_counter = 0\n",
    "        \n",
    "            \n",
    "\n",
    "        while queue:\n",
    "                queue = sorted(queue, key=lambda x:x[1])\n",
    "                current_node = queue.pop(0)[0]\n",
    "                g_queue = sorted(g_queue, key=lambda x:x[1])\n",
    "                current_g = g_queue.pop(0)[0]\n",
    "                #print(current_node.data)\n",
    "                \n",
    "                frontier.add(tuple(current_node.data.reshape(1,9)[0]))\n",
    "                iteration_counter += 1\n",
    "\n",
    "                if np.array_equal(current_node.data,goal_state):\n",
    "                    steps=current_node.without_result_manhattan()\n",
    "                    return steps,iteration_counter\n",
    "\n",
    "                else:              \n",
    "                    if current_node.possibility_R2():\n",
    "                        new_data,garbage = current_node.possibility_R2()\n",
    "                        if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                            cost_g = current_g+1\n",
    "                            temp = new_data\n",
    "                            goal_position_dic = {0:(0,0),1:(0,1),2:(0,2),3:(1,0),4:(1,1),5:(1,2),6:(2,0),7:(2,1),8:(2,2)}\n",
    "                            temp_h=0\n",
    "                            for i in range(3):\n",
    "                                for j in range(3):\n",
    "                                    if temp[i,j] != 0:\n",
    "                                        temp_h += sum(abs(a-b) for a,b in zip((i,j), goal_position_dic[temp[i,j]]))\n",
    "                                        \n",
    "                            total_cost = temp_h + cost_g\n",
    "                            current_node.R2 = Node_astar_manhattan(data=new_data,parent=current_node,cost_g=cost_g,cost_h=temp_h)\n",
    "                            queue.append((current_node.R2,total_cost))\n",
    "                            g_queue.append((cost_g,total_cost))\n",
    "\n",
    "                    if current_node.possibility_R1():\n",
    "                        new_data,garbage = current_node.possibility_R1()\n",
    "                        if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                            cost_g = current_g+1\n",
    "                            temp = new_data\n",
    "                            goal_position_dic = {0:(0,0),1:(0,1),2:(0,2),3:(1,0),4:(1,1),5:(1,2),6:(2,0),7:(2,1),8:(2,2)}\n",
    "                            temp_h=0\n",
    "                            for i in range(3):\n",
    "                                for j in range(3):\n",
    "                                    if temp[i,j] != 0:\n",
    "                                        temp_h += sum(abs(a-b) for a,b in zip((i,j), goal_position_dic[temp[i,j]]))\n",
    "                                        \n",
    "                            total_cost = temp_h + cost_g\n",
    "                            current_node.R1 = Node_astar_manhattan(data=new_data,parent=current_node,cost_g=cost_g,cost_h=temp_h)\n",
    "                            queue.append((current_node.R1,total_cost))\n",
    "                            g_queue.append((cost_g,total_cost))                               \n",
    "\n",
    "                    if current_node.possibility_L2():\n",
    "                        new_data,garbage = current_node.possibility_L2()\n",
    "                        if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                            cost_g = current_g+1\n",
    "                            temp = new_data\n",
    "                            goal_position_dic = {0:(0,0),1:(0,1),2:(0,2),3:(1,0),4:(1,1),5:(1,2),6:(2,0),7:(2,1),8:(2,2)}\n",
    "                            temp_h=0\n",
    "                            for i in range(3):\n",
    "                                for j in range(3):\n",
    "                                    if temp[i,j] != 0:\n",
    "                                        temp_h += sum(abs(a-b) for a,b in zip((i,j), goal_position_dic[temp[i,j]]))\n",
    "                            \n",
    "                            total_cost = temp_h + cost_g \n",
    "                            current_node.L2 = Node_astar_manhattan(data=new_data,parent=current_node,cost_g=cost_g,cost_h=temp_h)\n",
    "                            queue.append((current_node.L2,total_cost))\n",
    "                            g_queue.append((cost_g,total_cost))\n",
    "                                \n",
    "                    if current_node.possibility_L1():\n",
    "                        new_data,garbage = current_node.possibility_L1()\n",
    "                        if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                            cost_g = current_g+1\n",
    "                            temp = new_data\n",
    "                            goal_position_dic = {0:(0,0),1:(0,1),2:(0,2),3:(1,0),4:(1,1),5:(1,2),6:(2,0),7:(2,1),8:(2,2)}\n",
    "                            temp_h=0\n",
    "                            for i in range(3):\n",
    "                                for j in range(3):\n",
    "                                    if temp[i,j] != 0:\n",
    "                                        temp_h += sum(abs(a-b) for a,b in zip((i,j), goal_position_dic[temp[i,j]]))\n",
    "                            \n",
    "                            total_cost = temp_h + cost_g\n",
    "                            current_node.L1 = Node_astar_manhattan(data=new_data,parent=current_node,cost_g=cost_g,cost_h=temp_h)\n",
    "                            queue.append((current_node.L1,total_cost))\n",
    "                            g_queue.append((cost_g,total_cost))\n",
    "                                \n",
    "                                \n",
    "    def without_result_manhattan(self):\n",
    "        g_tracking = [self.cost_g]\n",
    "        \n",
    "        while self.parent:\n",
    "            self = self.parent\n",
    "            g_tracking.append(self.cost_g)\n",
    "        \n",
    "        return len(g_tracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#implementation of function \"breadthFirstSearch\" (for graduate students)\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "goal_state = np.array([[0, 1, 2],\n",
    "                       [3, 4, 5],\n",
    "                       [6, 7, 8]])\n",
    "class Node_BFS:\n",
    "    def __init__(self,data,parent,cost_g):\n",
    "        self.data = data\n",
    "        self.L1 = None\n",
    "        self.L2 = None\n",
    "        self.R1 = None\n",
    "        self.R2 = None\n",
    "        self.parent = parent\n",
    "        self.cost_g = cost_g\n",
    "    \n",
    "    def possibility_L1(self):\n",
    "        index_of_zero=np.where(self.data == 0)\n",
    "        if index_of_zero[1] == 0:\n",
    "            return False\n",
    "        else:\n",
    "            temp = self.data[index_of_zero[0],index_of_zero[1]-1]\n",
    "            new_data = self.data.copy()\n",
    "            new_data[index_of_zero[0],index_of_zero[1]] = temp\n",
    "            new_data[index_of_zero[0],index_of_zero[1]-1] = 0\n",
    "            return new_data,True\n",
    "       \n",
    "    \n",
    "    def possibility_L2(self):\n",
    "        index_of_zero=np.where(self.data == 0)\n",
    "        if index_of_zero[0] == 2:\n",
    "            return False\n",
    "        else:\n",
    "            temp = self.data[index_of_zero[0]+1,index_of_zero[1]]\n",
    "            new_data = self.data.copy()\n",
    "            new_data[index_of_zero[0],index_of_zero[1]] = temp\n",
    "            new_data[index_of_zero[0]+1,index_of_zero[1]] = 0\n",
    "            return new_data,True\n",
    "        \n",
    "        \n",
    "    def possibility_R1(self):\n",
    "        index_of_zero=np.where(self.data == 0)\n",
    "        if index_of_zero[1] == 2:\n",
    "            return False\n",
    "        else:\n",
    "            temp = self.data[index_of_zero[0],index_of_zero[1]+1]\n",
    "            new_data = self.data.copy()\n",
    "            new_data[index_of_zero[0],index_of_zero[1]] = temp\n",
    "            new_data[index_of_zero[0],index_of_zero[1]+1] = 0\n",
    "            return new_data,True\n",
    "            \n",
    "    def possibility_R2(self):\n",
    "        index_of_zero=np.where(self.data == 0)\n",
    "        if index_of_zero[0] == 0:\n",
    "            return False\n",
    "        else:\n",
    "            temp = self.data[index_of_zero[0]-1,index_of_zero[1]]\n",
    "            new_data = self.data.copy()\n",
    "            new_data[index_of_zero[0],index_of_zero[1]] = temp\n",
    "            new_data[index_of_zero[0]-1,index_of_zero[1]] = 0\n",
    "            return new_data,True\n",
    "        \n",
    "    def breadthFirstSearch(self):\n",
    "    \n",
    "            queue = [self] \n",
    "            frontier = set([]) \n",
    "            iteration_counter = 0\n",
    "            g_queue = [0]\n",
    "            while queue:\n",
    "\n",
    "                current_node = queue.pop(0) \n",
    "                current_g = g_queue.pop(0)\n",
    "                #print(current_node.data)\n",
    "                   \n",
    "                frontier.add(tuple(current_node.data.reshape(1,9)[0]))\n",
    "                iteration_counter += 1\n",
    "\n",
    "                if np.array_equal(current_node.data,goal_state):\n",
    "                    steps = current_node.print_BFS()\n",
    "                    return steps,iteration_counter\n",
    "\n",
    "                else:              \n",
    "                        if current_node.possibility_R2():\n",
    "                            new_data,garbage = current_node.possibility_R2()\n",
    "                    \n",
    "                            if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                                cost_g = current_g+1\n",
    "                                current_node.R2 = Node_BFS(data=new_data,parent=current_node,cost_g=cost_g)\n",
    "                                queue.append(current_node.R2)\n",
    "                                g_queue.append(cost_g)\n",
    "\n",
    "                        if current_node.possibility_R1():\n",
    "                            new_data,garbage = current_node.possibility_R1()\n",
    "                    \n",
    "                            if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                                cost_g = current_g+1\n",
    "                                current_node.R1 = Node_BFS(data=new_data,parent=current_node,cost_g=cost_g)\n",
    "                                queue.append(current_node.R1)\n",
    "                                g_queue.append(cost_g)\n",
    "                               \n",
    "\n",
    "                        if current_node.possibility_L2():\n",
    "                            new_data,garbage = current_node.possibility_L2()\n",
    "                    \n",
    "                            if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                                cost_g = current_g+1\n",
    "                                current_node.L2 = Node_BFS(data=new_data,parent=current_node,cost_g=cost_g)\n",
    "                                queue.append(current_node.L2)\n",
    "                                g_queue.append(cost_g)\n",
    "                                \n",
    "                                \n",
    "                        if current_node.possibility_L1():\n",
    "                            new_data,garbage = current_node.possibility_L1()\n",
    "                    \n",
    "                            if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                                cost_g = current_g+1\n",
    "                                current_node.L1 = Node_BFS(data=new_data,parent=current_node,cost_g=cost_g)\n",
    "                                queue.append(current_node.L1)\n",
    "                                g_queue.append(cost_g)\n",
    "                                \n",
    "                                \n",
    "    def print_BFS(self):\n",
    "        data_tracking = [self.data]\n",
    "        g_tracking = [self.cost_g]\n",
    "        \n",
    "        while self.parent:\n",
    "            self = self.parent\n",
    "            data_tracking.append(self.data)\n",
    "            g_tracking.append(self.cost_g)\n",
    "            \n",
    "        print ('Solution of the first Scenario(BFS):')\n",
    "        while data_tracking:\n",
    "            print (data_tracking.pop())\n",
    "            print ('to')           \n",
    "        return len(g_tracking)\n",
    "    \n",
    "    \n",
    "    def BFS_withoutprint(self):\n",
    "    \n",
    "            queue = [self] \n",
    "            frontier = set([]) \n",
    "            iteration_counter = 0\n",
    "            g_queue = [0]\n",
    "            while queue:\n",
    "\n",
    "                current_node = queue.pop(0) \n",
    "                current_g = g_queue.pop(0)\n",
    "                #print(current_node.data)\n",
    "                   \n",
    "                frontier.add(tuple(current_node.data.reshape(1,9)[0]))\n",
    "                iteration_counter += 1\n",
    "\n",
    "                if np.array_equal(current_node.data,goal_state):\n",
    "                    steps = current_node.withoutprint_BFS()\n",
    "                    return steps,iteration_counter\n",
    "\n",
    "                else:              \n",
    "                        if current_node.possibility_R2():\n",
    "                            new_data,garbage = current_node.possibility_R2()\n",
    "                    \n",
    "                            if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                                cost_g = current_g+1\n",
    "                                current_node.R2 = Node_BFS(data=new_data,parent=current_node,cost_g=cost_g)\n",
    "                                queue.append(current_node.R2)\n",
    "                                g_queue.append(cost_g)\n",
    "\n",
    "                        if current_node.possibility_R1():\n",
    "                            new_data,garbage = current_node.possibility_R1()\n",
    "                    \n",
    "                            if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                                cost_g = current_g+1\n",
    "                                current_node.R1 = Node_BFS(data=new_data,parent=current_node,cost_g=cost_g)\n",
    "                                queue.append(current_node.R1)\n",
    "                                g_queue.append(cost_g)\n",
    "                               \n",
    "\n",
    "                        if current_node.possibility_L2():\n",
    "                            new_data,garbage = current_node.possibility_L2()\n",
    "                    \n",
    "                            if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                                cost_g = current_g+1\n",
    "                                current_node.L2 = Node_BFS(data=new_data,parent=current_node,cost_g=cost_g)\n",
    "                                queue.append(current_node.L2)\n",
    "                                g_queue.append(cost_g)\n",
    "                                \n",
    "                                \n",
    "                        if current_node.possibility_L1():\n",
    "                            new_data,garbage = current_node.possibility_L1()\n",
    "                    \n",
    "                            if tuple(new_data.reshape(1,9)[0]) not in frontier:\n",
    "                                cost_g = current_g+1\n",
    "                                current_node.L1 = Node_BFS(data=new_data,parent=current_node,cost_g=cost_g)\n",
    "                                queue.append(current_node.L1)\n",
    "                                g_queue.append(cost_g)\n",
    "                                \n",
    "                                \n",
    "    def withoutprint_BFS(self):\n",
    "        g_tracking = [self.cost_g]\n",
    "        \n",
    "        while self.parent:\n",
    "            self = self.parent\n",
    "            g_tracking.append(self.cost_g)\n",
    "                  \n",
    "        return len(g_tracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#implementation of function \"print_result(result)\"\n",
    "\n",
    "def print_result():\n",
    "    #for Iterative_DFS\n",
    "    file = open(\"File Input8PuzzleCases.txt\")\n",
    "    caselist=[]\n",
    "    index=0\n",
    "    for line in file:\n",
    "        string=line.strip(\"\\n\").split(\",\")\n",
    "        caselist.append([])\n",
    "        for j in range (len(string)):\n",
    "            caselist[index].append(int(string[j]))\n",
    "        index+=1\n",
    "\n",
    "    time_spend_DFS = []\n",
    "    steps_track_DFS=[]\n",
    "    iteration_track_DFS = []\n",
    "\n",
    "    test = np.array(caselist.pop(0)).reshape((3,3))\n",
    "    root=Node_DFS(data=test,parent=None,cost_g=0)\n",
    "\n",
    "    start = time.time()\n",
    "        #------------------------function call----------------------------\n",
    "    steps,iteration_counter = root.Iterative_deepening_DFS()\n",
    "    time_spend_DFS.append(time.time()-start)\n",
    "    steps_track_DFS.append(steps)\n",
    "    iteration_track_DFS.append(iteration_counter)\n",
    "\n",
    "    for i in range(99):\n",
    "\n",
    "        test = np.array(caselist.pop(0)).reshape((3,3))\n",
    "        root=Node_DFS(data=test,parent=None,cost_g=0)\n",
    "\n",
    "        start = time.time()\n",
    "        steps,iteration_counter = root.deepeningDFS_withoutprint()\n",
    "        time_spend_DFS.append(time.time()-start)\n",
    "        steps_track_DFS.append(steps)\n",
    "        iteration_track_DFS.append(iteration_counter)\n",
    "        \n",
    "    #FOR ASTAR_MISPLACED\n",
    "    file = open(\"File Input8PuzzleCases.txt\")\n",
    "    caselist=[]\n",
    "    index=0\n",
    "    for line in file:\n",
    "        string=line.strip(\"\\n\").split(\",\")\n",
    "        caselist.append([])\n",
    "        for j in range (len(string)):\n",
    "            caselist[index].append(int(string[j]))\n",
    "        index+=1\n",
    "\n",
    "    time_spend_AMIS = []\n",
    "    steps_track_AMIS=[]\n",
    "    iteration_track_AMIS = []\n",
    "\n",
    "    test = np.array(caselist.pop(0)).reshape((3,3))\n",
    "    root=Node_astar_misplaced(data=test,parent=None,cost_g=0,cost_h=0)\n",
    "\n",
    "    start = time.time()\n",
    "    #------------------------function call----------------------------\n",
    "    steps,iteration_counter = root.aStarMisplacedTiles()\n",
    "    time_spend_AMIS.append(time.time()-start)\n",
    "    steps_track_AMIS.append(steps)\n",
    "    iteration_track_AMIS.append(iteration_counter)\n",
    "\n",
    "    for i in range(99):\n",
    "\n",
    "        test = np.array(caselist.pop(0)).reshape((3,3))\n",
    "        root=Node_astar_misplaced(data=test,parent=None,cost_g=0,cost_h=0)\n",
    "\n",
    "        start = time.time()\n",
    "        #---------------\n",
    "        steps,iteration_counter = root.astar_misplaced_withoutprint()\n",
    "        time_spend_AMIS.append(time.time()-start)\n",
    "        steps_track_AMIS.append(steps)\n",
    "        iteration_track_AMIS.append(iteration_counter)\n",
    "        \n",
    "    # FOR ASTAR_MANHATTAN\n",
    "    file = open(\"File Input8PuzzleCases.txt\")\n",
    "    caselist=[]\n",
    "    index=0\n",
    "    for line in file:\n",
    "        string=line.strip(\"\\n\").split(\",\")\n",
    "        caselist.append([])\n",
    "        for j in range (len(string)):\n",
    "            caselist[index].append(int(string[j]))\n",
    "        index+=1\n",
    "\n",
    "    time_spend_AMAN = []\n",
    "    steps_track_AMAN=[]\n",
    "    iteration_track_AMAN = []\n",
    "\n",
    "    test = np.array(caselist.pop(0)).reshape((3,3))\n",
    "    root=Node_astar_manhattan(data=test,parent=None,cost_g=0,cost_h=0)\n",
    "\n",
    "    start = time.time()\n",
    "        #------------------------function call----------------------------\n",
    "    steps,iteration_counter = root.aStarManhattanDistance()\n",
    "    time_spend_AMAN.append(time.time()-start)\n",
    "    steps_track_AMAN.append(steps)\n",
    "    iteration_track_AMAN.append(iteration_counter)\n",
    "\n",
    "    for i in range(99):\n",
    "\n",
    "        test = np.array(caselist.pop(0)).reshape((3,3))\n",
    "        root=Node_astar_manhattan(data=test,parent=None,cost_g=0,cost_h=0)\n",
    "\n",
    "        start = time.time()\n",
    "        #--------------\n",
    "        steps,iteration_counter = root.astar_manhattan_withoutprint()\n",
    "        time_spend_AMAN.append(time.time()-start)\n",
    "        steps_track_AMAN.append(steps)\n",
    "        iteration_track_AMAN.append(iteration_counter)\n",
    "        \n",
    "    # FOR BFS\n",
    "    file = open(\"File Input8PuzzleCases.txt\")\n",
    "    caselist=[]\n",
    "    index=0\n",
    "    for line in file:\n",
    "        string=line.strip(\"\\n\").split(\",\")\n",
    "        caselist.append([])\n",
    "        for j in range (len(string)):\n",
    "            caselist[index].append(int(string[j]))\n",
    "        index+=1\n",
    "\n",
    "    time_spend_BFS = []\n",
    "    steps_track_BFS=[]\n",
    "    iteration_track_BFS = []\n",
    "\n",
    "    test = np.array(caselist.pop(0)).reshape((3,3))\n",
    "    root=Node_BFS(data=test,parent=None,cost_g=0)\n",
    "\n",
    "    start = time.time()\n",
    "        #------------------------function call----------------------------\n",
    "    steps,iteration_counter = root.breadthFirstSearch()\n",
    "    time_spend_BFS.append(time.time()-start)\n",
    "    steps_track_BFS.append(steps)\n",
    "    iteration_track_BFS.append(iteration_counter)\n",
    "\n",
    "    for i in range(19):\n",
    "\n",
    "        test = np.array(caselist.pop(0)).reshape((3,3))\n",
    "        root=Node_BFS(data=test,parent=None,cost_g=0)\n",
    "\n",
    "        start = time.time()\n",
    "        #-------------\n",
    "        steps,iteration_counter = root.BFS_withoutprint()\n",
    "        time_spend_BFS.append(time.time()-start)\n",
    "        steps_track_BFS.append(steps)\n",
    "        iteration_track_BFS.append(iteration_counter)\n",
    "        \n",
    "        \n",
    "        \n",
    "    print('\\t\\t\\t\\t Average_Steps \\t Average_Time \\t Average_Iterations')\n",
    "    print('\\t Iterative DFS \\t ', sum(steps_track_DFS)/100, ' \\t ', sum(time_spend_DFS)/100, ' \\t ', sum(iteration_track_DFS)/100)\n",
    "    print('\\t A*(Misplaced) \\t ', sum(steps_track_AMIS)/100, ' \\t ', sum(time_spend_AMIS)/100, ' \\t ', sum(iteration_track_AMIS)/100)\n",
    "    print('\\t A*(Manhattan) \\t ', sum(steps_track_AMAN)/100, ' \\t ', sum(time_spend_AMAN)/100, ' \\t ', sum(iteration_track_AMAN)/100)\n",
    "    print('\\t BFS \\t\\t ', sum(steps_track_BFS)/20, ' \\t ', sum(time_spend_BFS)/20, ' \\t ', sum(iteration_track_BFS)/20)\n",
    "    \n",
    "    return steps_track_DFS,time_spend_DFS,iteration_track_DFS,steps_track_AMIS,time_spend_AMIS,iteration_track_AMIS,steps_track_AMAN,time_spend_AMAN,iteration_track_AMAN,steps_track_BFS,time_spend_BFS,iteration_track_BFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution of the first Scenario(IterativeDFS):\n",
      "[[8 7 5]\n",
      " [4 1 2]\n",
      " [3 0 6]]\n",
      "to\n",
      "[[8 7 5]\n",
      " [4 1 2]\n",
      " [0 3 6]]\n",
      "to\n",
      "[[8 7 5]\n",
      " [0 1 2]\n",
      " [4 3 6]]\n",
      "to\n",
      "[[8 7 5]\n",
      " [1 0 2]\n",
      " [4 3 6]]\n",
      "to\n",
      "[[8 7 5]\n",
      " [1 3 2]\n",
      " [4 0 6]]\n",
      "to\n",
      "[[8 7 5]\n",
      " [1 3 2]\n",
      " [0 4 6]]\n",
      "to\n",
      "[[8 7 5]\n",
      " [0 3 2]\n",
      " [1 4 6]]\n",
      "to\n",
      "[[8 7 5]\n",
      " [3 0 2]\n",
      " [1 4 6]]\n",
      "to\n",
      "[[8 0 5]\n",
      " [3 7 2]\n",
      " [1 4 6]]\n",
      "to\n",
      "[[0 8 5]\n",
      " [3 7 2]\n",
      " [1 4 6]]\n",
      "to\n",
      "[[3 8 5]\n",
      " [0 7 2]\n",
      " [1 4 6]]\n",
      "to\n",
      "[[3 8 5]\n",
      " [1 7 2]\n",
      " [0 4 6]]\n",
      "to\n",
      "[[3 8 5]\n",
      " [1 7 2]\n",
      " [4 0 6]]\n",
      "to\n",
      "[[3 8 5]\n",
      " [1 7 2]\n",
      " [4 6 0]]\n",
      "to\n",
      "[[3 8 5]\n",
      " [1 7 0]\n",
      " [4 6 2]]\n",
      "to\n",
      "[[3 8 5]\n",
      " [1 0 7]\n",
      " [4 6 2]]\n",
      "to\n",
      "[[3 0 5]\n",
      " [1 8 7]\n",
      " [4 6 2]]\n",
      "to\n",
      "[[0 3 5]\n",
      " [1 8 7]\n",
      " [4 6 2]]\n",
      "to\n",
      "[[1 3 5]\n",
      " [0 8 7]\n",
      " [4 6 2]]\n",
      "to\n",
      "[[1 3 5]\n",
      " [4 8 7]\n",
      " [0 6 2]]\n",
      "to\n",
      "[[1 3 5]\n",
      " [4 8 7]\n",
      " [6 0 2]]\n",
      "to\n",
      "[[1 3 5]\n",
      " [4 8 7]\n",
      " [6 2 0]]\n",
      "to\n",
      "[[1 3 5]\n",
      " [4 8 0]\n",
      " [6 2 7]]\n",
      "to\n",
      "[[1 3 5]\n",
      " [4 0 8]\n",
      " [6 2 7]]\n",
      "to\n",
      "[[1 3 5]\n",
      " [4 2 8]\n",
      " [6 0 7]]\n",
      "to\n",
      "[[1 3 5]\n",
      " [4 2 8]\n",
      " [0 6 7]]\n",
      "to\n",
      "[[1 3 5]\n",
      " [0 2 8]\n",
      " [4 6 7]]\n",
      "to\n",
      "[[0 3 5]\n",
      " [1 2 8]\n",
      " [4 6 7]]\n",
      "to\n",
      "[[3 0 5]\n",
      " [1 2 8]\n",
      " [4 6 7]]\n",
      "to\n",
      "[[3 2 5]\n",
      " [1 0 8]\n",
      " [4 6 7]]\n",
      "to\n",
      "[[3 2 5]\n",
      " [0 1 8]\n",
      " [4 6 7]]\n",
      "to\n",
      "[[3 2 5]\n",
      " [4 1 8]\n",
      " [0 6 7]]\n",
      "to\n",
      "[[3 2 5]\n",
      " [4 1 8]\n",
      " [6 0 7]]\n",
      "to\n",
      "[[3 2 5]\n",
      " [4 1 8]\n",
      " [6 7 0]]\n",
      "to\n",
      "[[3 2 5]\n",
      " [4 1 0]\n",
      " [6 7 8]]\n",
      "to\n",
      "[[3 2 0]\n",
      " [4 1 5]\n",
      " [6 7 8]]\n",
      "to\n",
      "[[3 0 2]\n",
      " [4 1 5]\n",
      " [6 7 8]]\n",
      "to\n",
      "[[3 1 2]\n",
      " [4 0 5]\n",
      " [6 7 8]]\n",
      "to\n",
      "[[3 1 2]\n",
      " [0 4 5]\n",
      " [6 7 8]]\n",
      "to\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "to\n",
      "Solution of the first Scenario(astr_misplaced):\n",
      "[[8 7 5]\n",
      " [4 1 2]\n",
      " [3 0 6]]\n",
      "to\n",
      "[[8 7 5]\n",
      " [4 0 2]\n",
      " [3 1 6]]\n",
      "to\n",
      "[[8 7 5]\n",
      " [4 2 0]\n",
      " [3 1 6]]\n",
      "to\n",
      "[[8 7 0]\n",
      " [4 2 5]\n",
      " [3 1 6]]\n",
      "to\n",
      "[[8 0 7]\n",
      " [4 2 5]\n",
      " [3 1 6]]\n",
      "to\n",
      "[[8 2 7]\n",
      " [4 0 5]\n",
      " [3 1 6]]\n",
      "to\n",
      "[[8 2 7]\n",
      " [4 1 5]\n",
      " [3 0 6]]\n",
      "to\n",
      "[[8 2 7]\n",
      " [4 1 5]\n",
      " [3 6 0]]\n",
      "to\n",
      "[[8 2 7]\n",
      " [4 1 0]\n",
      " [3 6 5]]\n",
      "to\n",
      "[[8 2 0]\n",
      " [4 1 7]\n",
      " [3 6 5]]\n",
      "to\n",
      "[[8 0 2]\n",
      " [4 1 7]\n",
      " [3 6 5]]\n",
      "to\n",
      "[[0 8 2]\n",
      " [4 1 7]\n",
      " [3 6 5]]\n",
      "to\n",
      "[[4 8 2]\n",
      " [0 1 7]\n",
      " [3 6 5]]\n",
      "to\n",
      "[[4 8 2]\n",
      " [1 0 7]\n",
      " [3 6 5]]\n",
      "to\n",
      "[[4 0 2]\n",
      " [1 8 7]\n",
      " [3 6 5]]\n",
      "to\n",
      "[[0 4 2]\n",
      " [1 8 7]\n",
      " [3 6 5]]\n",
      "to\n",
      "[[1 4 2]\n",
      " [0 8 7]\n",
      " [3 6 5]]\n",
      "to\n",
      "[[1 4 2]\n",
      " [3 8 7]\n",
      " [0 6 5]]\n",
      "to\n",
      "[[1 4 2]\n",
      " [3 8 7]\n",
      " [6 0 5]]\n",
      "to\n",
      "[[1 4 2]\n",
      " [3 0 7]\n",
      " [6 8 5]]\n",
      "to\n",
      "[[1 4 2]\n",
      " [3 7 0]\n",
      " [6 8 5]]\n",
      "to\n",
      "[[1 4 2]\n",
      " [3 7 5]\n",
      " [6 8 0]]\n",
      "to\n",
      "[[1 4 2]\n",
      " [3 7 5]\n",
      " [6 0 8]]\n",
      "to\n",
      "[[1 4 2]\n",
      " [3 0 5]\n",
      " [6 7 8]]\n",
      "to\n",
      "[[1 0 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "to\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "to\n"
     ]
    }
   ],
   "source": [
    "#you need to implement print_result function to print out the result according to the required format\n",
    "steps_track_DFS,time_spend_DFS,iteration_track_DFS,steps_track_AMIS,time_spend_AMIS,iteration_track_AMIS,steps_track_AMAN,time_spend_AMAN,iteration_track_AMAN,steps_track_BFS,time_spend_BFS,iteration_track_BFS=print_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can insert as many cells as you want above\n",
    "You are not Allowed to modify the code below this line.\n",
    "==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#you need to implement print_result function to print out the result according to the required format\n",
    "print_result(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The output format should be as follows. You only need to give one sample solution as an example.\n",
    "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "Solution of the first Scenario:\n",
    "X X X\n",
    "X X X\n",
    "X X X\n",
    "to\n",
    "X X X\n",
    "X X X\n",
    "X X X\n",
    "to\n",
    "X X X\n",
    "X X X\n",
    "X X X\n",
    "to\n",
    "X X X\n",
    "X X X\n",
    "X X X\n",
    "to\n",
    ".\n",
    ".\n",
    ".\n",
    "0 1 2\n",
    "3 4 5\n",
    "6 7 8\n",
    "\n",
    "                Average_Steps    Average_Time   Average_Iterations   \n",
    "UCS\n",
    "A*(Misplaced)\n",
    "A*(Manhattan)\n",
    "BFS\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
